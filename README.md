# hey, what's that?

It's just a bunch of python scripts. Together they:
a) harvest emotions dataset to extract faces from it in normalized way (same size, grey colours)
a) teach a model to classificate emotions
b) swap faces to emoticons in real-time (using video stream from a webcam)

# how can I use it?

To see it in action you need:
a) python
b) opencv
[c)] dataset to teach a model, but you can used a model teached on http://www.consortium.ri.cmu.edu/ckagree/

# screenshots

# credits
todo
